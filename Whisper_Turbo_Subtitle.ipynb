{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7p4rTbS6kxIo",
        "outputId": "cdd3d4bd-edf2-4de2-ab74-ea70c8afa95c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://2b26a79b3ad220130d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://2b26a79b3ad220130d.gradio.live\n"
          ]
        }
      ],
      "source": [
        "#@title Run App\n",
        "!git clone https://github.com/NeuralFalconYT/Whisper-Turbo-Subtitle.git\n",
        "%cd Whisper-Turbo-Subtitle\n",
        "!pip install -r requirements.txt\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "!python app.py --share"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "language_dict = {\n",
        "    \"Akan\": {\"lang_code\": \"aka\", \"meta_code\": \"aka_Latn\"},\n",
        "    \"Albanian\": {\"lang_code\": \"sq\", \"meta_code\": \"als_Latn\"},\n",
        "    \"Amharic\": {\"lang_code\": \"am\", \"meta_code\": \"amh_Ethi\"},\n",
        "    \"Arabic\": {\"lang_code\": \"ar\", \"meta_code\": \"arb_Arab\"},\n",
        "    \"Armenian\": {\"lang_code\": \"hy\", \"meta_code\": \"hye_Armn\"},\n",
        "    \"Assamese\": {\"lang_code\": \"as\", \"meta_code\": \"asm_Beng\"},\n",
        "    \"Azerbaijani\": {\"lang_code\": \"az\", \"meta_code\": \"azj_Latn\"},\n",
        "    \"Basque\": {\"lang_code\": \"eu\", \"meta_code\": \"eus_Latn\"},\n",
        "    \"Bashkir\": {\"lang_code\": \"ba\", \"meta_code\": \"bak_Cyrl\"},\n",
        "    \"Bengali\": {\"lang_code\": \"bn\", \"meta_code\": \"ben_Beng\"},\n",
        "    \"Bosnian\": {\"lang_code\": \"bs\", \"meta_code\": \"bos_Latn\"},\n",
        "    \"Bulgarian\": {\"lang_code\": \"bg\", \"meta_code\": \"bul_Cyrl\"},\n",
        "    \"Burmese\": {\"lang_code\": \"my\", \"meta_code\": \"mya_Mymr\"},\n",
        "    \"Catalan\": {\"lang_code\": \"ca\", \"meta_code\": \"cat_Latn\"},\n",
        "    \"Chinese\": {\"lang_code\": \"zh\", \"meta_code\": \"zh_Hans\"},\n",
        "    \"Croatian\": {\"lang_code\": \"hr\", \"meta_code\": \"hrv_Latn\"},\n",
        "    \"Czech\": {\"lang_code\": \"cs\", \"meta_code\": \"ces_Latn\"},\n",
        "    \"Danish\": {\"lang_code\": \"da\", \"meta_code\": \"dan_Latn\"},\n",
        "    \"Dutch\": {\"lang_code\": \"nl\", \"meta_code\": \"nld_Latn\"},\n",
        "    \"English\": {\"lang_code\": \"en\", \"meta_code\": \"eng_Latn\"},\n",
        "    \"Estonian\": {\"lang_code\": \"et\", \"meta_code\": \"est_Latn\"},\n",
        "    \"Faroese\": {\"lang_code\": \"fo\", \"meta_code\": \"fao_Latn\"},\n",
        "    \"Finnish\": {\"lang_code\": \"fi\", \"meta_code\": \"fin_Latn\"},\n",
        "    \"French\": {\"lang_code\": \"fr\", \"meta_code\": \"fra_Latn\"},\n",
        "    \"Galician\": {\"lang_code\": \"gl\", \"meta_code\": \"glg_Latn\"},\n",
        "    \"Georgian\": {\"lang_code\": \"ka\", \"meta_code\": \"kat_Geor\"},\n",
        "    \"German\": {\"lang_code\": \"de\", \"meta_code\": \"deu_Latn\"},\n",
        "    \"Greek\": {\"lang_code\": \"el\", \"meta_code\": \"ell_Grek\"},\n",
        "    \"Gujarati\": {\"lang_code\": \"gu\", \"meta_code\": \"guj_Gujr\"},\n",
        "    \"Haitian Creole\": {\"lang_code\": \"ht\", \"meta_code\": \"hat_Latn\"},\n",
        "    \"Hausa\": {\"lang_code\": \"ha\", \"meta_code\": \"hau_Latn\"},\n",
        "    \"Hebrew\": {\"lang_code\": \"he\", \"meta_code\": \"heb_Hebr\"},\n",
        "    \"Hindi\": {\"lang_code\": \"hi\", \"meta_code\": \"hin_Deva\"},\n",
        "    \"Hungarian\": {\"lang_code\": \"hu\", \"meta_code\": \"hun_Latn\"},\n",
        "    \"Icelandic\": {\"lang_code\": \"is\", \"meta_code\": \"isl_Latn\"},\n",
        "    \"Indonesian\": {\"lang_code\": \"id\", \"meta_code\": \"ind_Latn\"},\n",
        "    \"Italian\": {\"lang_code\": \"it\", \"meta_code\": \"ita_Latn\"},\n",
        "    \"Japanese\": {\"lang_code\": \"ja\", \"meta_code\": \"jpn_Jpan\"},\n",
        "    \"Kannada\": {\"lang_code\": \"kn\", \"meta_code\": \"kan_Knda\"},\n",
        "    \"Kazakh\": {\"lang_code\": \"kk\", \"meta_code\": \"kaz_Cyrl\"},\n",
        "    \"Korean\": {\"lang_code\": \"ko\", \"meta_code\": \"kor_Hang\"},\n",
        "    \"Kurdish\": {\"lang_code\": \"ckb\", \"meta_code\": \"ckb_Arab\"},\n",
        "    \"Kyrgyz\": {\"lang_code\": \"ky\", \"meta_code\": \"kir_Cyrl\"},\n",
        "    \"Lao\": {\"lang_code\": \"lo\", \"meta_code\": \"lao_Laoo\"},\n",
        "    \"Lithuanian\": {\"lang_code\": \"lt\", \"meta_code\": \"lit_Latn\"},\n",
        "    \"Luxembourgish\": {\"lang_code\": \"lb\", \"meta_code\": \"ltz_Latn\"},\n",
        "    \"Macedonian\": {\"lang_code\": \"mk\", \"meta_code\": \"mkd_Cyrl\"},\n",
        "    \"Malay\": {\"lang_code\": \"ms\", \"meta_code\": \"ms_Latn\"},\n",
        "    \"Malayalam\": {\"lang_code\": \"ml\", \"meta_code\": \"mal_Mlym\"},\n",
        "    \"Maltese\": {\"lang_code\": \"mt\", \"meta_code\": \"mlt_Latn\"},\n",
        "    \"Maori\": {\"lang_code\": \"mi\", \"meta_code\": \"mri_Latn\"},\n",
        "    \"Marathi\": {\"lang_code\": \"mr\", \"meta_code\": \"mar_Deva\"},\n",
        "    \"Mongolian\": {\"lang_code\": \"mn\", \"meta_code\": \"khk_Cyrl\"},\n",
        "    \"Nepali\": {\"lang_code\": \"ne\", \"meta_code\": \"npi_Deva\"},\n",
        "    \"Norwegian\": {\"lang_code\": \"no\", \"meta_code\": \"nob_Latn\"},\n",
        "    \"Norwegian Nynorsk\": {\"lang_code\": \"nn\", \"meta_code\": \"nno_Latn\"},\n",
        "    \"Pashto\": {\"lang_code\": \"ps\", \"meta_code\": \"pbt_Arab\"},\n",
        "    \"Persian\": {\"lang_code\": \"fa\", \"meta_code\": \"pes_Arab\"},\n",
        "    \"Polish\": {\"lang_code\": \"pl\", \"meta_code\": \"pol_Latn\"},\n",
        "    \"Portuguese\": {\"lang_code\": \"pt\", \"meta_code\": \"por_Latn\"},\n",
        "    \"Punjabi\": {\"lang_code\": \"pa\", \"meta_code\": \"pan_Guru\"},\n",
        "    \"Romanian\": {\"lang_code\": \"ro\", \"meta_code\": \"ron_Latn\"},\n",
        "    \"Russian\": {\"lang_code\": \"ru\", \"meta_code\": \"rus_Cyrl\"},\n",
        "    \"Serbian\": {\"lang_code\": \"sr\", \"meta_code\": \"srp_Cyrl\"},\n",
        "    \"Sinhala\": {\"lang_code\": \"si\", \"meta_code\": \"sin_Sinh\"},\n",
        "    \"Slovak\": {\"lang_code\": \"sk\", \"meta_code\": \"slk_Latn\"},\n",
        "    \"Slovenian\": {\"lang_code\": \"sl\", \"meta_code\": \"slv_Latn\"},\n",
        "    \"Somali\": {\"lang_code\": \"so\", \"meta_code\": \"som_Latn\"},\n",
        "    \"Spanish\": {\"lang_code\": \"es\", \"meta_code\": \"spa_Latn\"},\n",
        "    \"Sundanese\": {\"lang_code\": \"su\", \"meta_code\": \"sun_Latn\"},\n",
        "    \"Swahili\": {\"lang_code\": \"sw\", \"meta_code\": \"swa_Latn\"},\n",
        "    \"Swedish\": {\"lang_code\": \"sv\", \"meta_code\": \"swe_Latn\"},\n",
        "    \"Tamil\": {\"lang_code\": \"ta\", \"meta_code\": \"tam_Taml\"},\n",
        "    \"Telugu\": {\"lang_code\": \"te\", \"meta_code\": \"tel_Telu\"},\n",
        "    \"Thai\": {\"lang_code\": \"th\", \"meta_code\": \"tha_Latn\"},\n",
        "    \"Turkish\": {\"lang_code\": \"tr\", \"meta_code\": \"tur_Latn\"},\n",
        "    \"Ukrainian\": {\"lang_code\": \"uk\", \"meta_code\": \"ukr_Cyrl\"},\n",
        "    \"Urdu\": {\"lang_code\": \"ur\", \"meta_code\": \"urd_Arab\"},\n",
        "    \"Uzbek\": {\"lang_code\": \"uz\", \"meta_code\": \"uzb_Latn\"},\n",
        "    \"Vietnamese\": {\"lang_code\": \"vi\", \"meta_code\": \"vie_Latn\"},\n",
        "    \"Welsh\": {\"lang_code\": \"cy\", \"meta_code\": \"cym_Latn\"},\n",
        "    \"Yiddish\": {\"lang_code\": \"yi\", \"meta_code\": \"yi_Hebr\"},\n",
        "    \"Yoruba\": {\"lang_code\": \"yo\", \"meta_code\": \"yo_Latn\"},\n",
        "    \"Zulu\": {\"lang_code\": \"zu\", \"meta_code\": \"zul_Latn\"},\n",
        "}"
      ],
      "metadata": {
        "id": "bJBO4Rw802uF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import language_dict\n",
        "import math\n",
        "import torch\n",
        "import gc\n",
        "import time\n",
        "from faster_whisper import WhisperModel\n",
        "import os\n",
        "import re\n",
        "import uuid\n",
        "import shutil\n",
        "\n",
        "\n",
        "def get_language_name(lang_code):\n",
        "    global language_dict\n",
        "    # Iterate through the language dictionary\n",
        "    for language, details in language_dict.items():\n",
        "        # Check if the language code matches\n",
        "        if details[\"lang_code\"] == lang_code:\n",
        "            return language  # Return the language name\n",
        "    return lang_code\n",
        "\n",
        "def clean_file_name(file_path):\n",
        "    # Get the base file name and extension\n",
        "    file_name = os.path.basename(file_path)\n",
        "    file_name, file_extension = os.path.splitext(file_name)\n",
        "\n",
        "    # Replace non-alphanumeric characters with an underscore\n",
        "    cleaned = re.sub(r'[^a-zA-Z\\d]+', '_', file_name)\n",
        "\n",
        "    # Remove any multiple underscores\n",
        "    clean_file_name = re.sub(r'_+', '_', cleaned).strip('_')\n",
        "\n",
        "    # Generate a random UUID for uniqueness\n",
        "    random_uuid = uuid.uuid4().hex[:6]\n",
        "\n",
        "    # Combine cleaned file name with the original extension\n",
        "    clean_file_path = os.path.join(os.path.dirname(file_path), clean_file_name + f\"_{random_uuid}\" + file_extension)\n",
        "\n",
        "    return clean_file_path\n",
        "\n",
        "\n",
        "\n",
        "def format_segments(segments):\n",
        "    saved_segments = list(segments)\n",
        "    sentence_timestamp = []\n",
        "    words_timestamp = []\n",
        "    speech_to_text = \"\"\n",
        "\n",
        "    for i in saved_segments:\n",
        "        temp_sentence_timestamp = {}\n",
        "        # Store sentence information in sentence_timestamp\n",
        "        text = i.text.strip()\n",
        "        sentence_id = len(sentence_timestamp)  # Get the current index for the new entry\n",
        "        sentence_timestamp.append({\n",
        "            \"id\": sentence_id,  # Use the index as the id\n",
        "            \"text\": text,\n",
        "            \"start\": i.start,\n",
        "            \"end\": i.end,\n",
        "            \"words\": []  # Initialize words as an empty list within the sentence\n",
        "        })\n",
        "        speech_to_text += text + \" \"\n",
        "\n",
        "        # Process each word in the sentence\n",
        "        for word in i.words:\n",
        "            word_data = {\n",
        "                \"word\": word.word.strip(),\n",
        "                \"start\": word.start,\n",
        "                \"end\": word.end\n",
        "            }\n",
        "\n",
        "            # Append word timestamps to the sentence's word list\n",
        "            sentence_timestamp[sentence_id][\"words\"].append(word_data)\n",
        "\n",
        "            # Optionally, add the word data to the global words_timestamp list\n",
        "            words_timestamp.append(word_data)\n",
        "\n",
        "    return sentence_timestamp, words_timestamp, speech_to_text\n",
        "\n",
        "def combine_word_segments(words_timestamp, max_words_per_subtitle=8, min_silence_between_words=0.5):\n",
        "    if max_words_per_subtitle<=1:\n",
        "        max_words_per_subtitle=1\n",
        "    before_translate = {}\n",
        "    id = 1\n",
        "    text = \"\"\n",
        "    start = None\n",
        "    end = None\n",
        "    word_count = 0\n",
        "    last_end_time = None\n",
        "\n",
        "    for i in words_timestamp:\n",
        "        try:\n",
        "            word = i['word']\n",
        "            word_start = i['start']\n",
        "            word_end = i['end']\n",
        "\n",
        "            # Check for sentence-ending punctuation\n",
        "            is_end_of_sentence = word.endswith(('.', '?', '!'))\n",
        "\n",
        "            # Check for conditions to create a new subtitle\n",
        "            if ((last_end_time is not None and word_start - last_end_time > min_silence_between_words)\n",
        "                or word_count >= max_words_per_subtitle\n",
        "                or is_end_of_sentence):\n",
        "\n",
        "                # Store the previous subtitle if there's any\n",
        "                if text:\n",
        "                    before_translate[id] = {\n",
        "                        \"text\": text,\n",
        "                        \"start\": start,\n",
        "                        \"end\": end\n",
        "                    }\n",
        "                    id += 1\n",
        "\n",
        "                # Reset for the new subtitle segment\n",
        "                text = word\n",
        "                start = word_start  # Set the start time for the new subtitle\n",
        "                word_count = 1\n",
        "            else:\n",
        "                if word_count == 0:  # First word in the subtitle\n",
        "                    start = word_start  # Ensure the start time is set\n",
        "                text += \" \" + word\n",
        "                word_count += 1\n",
        "\n",
        "            end = word_end  # Update the end timestamp\n",
        "            last_end_time = word_end  # Update the last end timestamp\n",
        "\n",
        "        except KeyError as e:\n",
        "            print(f\"KeyError: {e} - Skipping word\")\n",
        "            pass\n",
        "\n",
        "    # After the loop, make sure to add the last subtitle segment\n",
        "    if text:\n",
        "        before_translate[id] = {\n",
        "            \"text\": text,\n",
        "            \"start\": start,\n",
        "            \"end\": end\n",
        "        }\n",
        "\n",
        "    return before_translate\n",
        "\n",
        "def custom_word_segments(words_timestamp, min_silence_between_words=0.3, max_characters_per_subtitle=17):\n",
        "    before_translate = []\n",
        "    id = 1\n",
        "    text = \"\"\n",
        "    start = None\n",
        "    end = None\n",
        "    last_end_time = None\n",
        "\n",
        "    i = 0\n",
        "    while i < len(words_timestamp):\n",
        "        word = words_timestamp[i]['word']\n",
        "        word_start = words_timestamp[i]['start']\n",
        "        word_end = words_timestamp[i]['end']\n",
        "\n",
        "        # Look ahead to check if the next word (i+1) starts with a hyphen\n",
        "        if i + 1 < len(words_timestamp) and words_timestamp[i + 1]['word'].startswith(\"-\"):\n",
        "            # Combine the current word and the next word (i, i+1) if next word starts with a hyphen\n",
        "            combined_text = word + words_timestamp[i + 1]['word'][:]  # Skip the hyphen and combine\n",
        "            combined_start_time = word_start\n",
        "            combined_end_time = words_timestamp[i + 1]['end']\n",
        "\n",
        "            i += 1  # Skip the next word (i+1) since it has been combined\n",
        "\n",
        "            # Look ahead for the next non-hyphenated word, check further if needed (i+2, i+3, etc.)\n",
        "            while i + 1 < len(words_timestamp) and words_timestamp[i + 1]['word'].startswith(\"-\"):\n",
        "                combined_text += words_timestamp[i + 1]['word'][:]  # Add word excluding hyphen\n",
        "                combined_end_time = words_timestamp[i + 1]['end']\n",
        "                i += 1  # Skip the next hyphenated word\n",
        "\n",
        "        else:\n",
        "            # No hyphen at the next word, just take the current word\n",
        "            combined_text = word\n",
        "            combined_start_time = word_start\n",
        "            combined_end_time = word_end\n",
        "\n",
        "        # Check if the combined text exceeds the maximum character limit\n",
        "        if len(text) + len(combined_text) > max_characters_per_subtitle:\n",
        "            # If accumulated text is non-empty, store it as a subtitle\n",
        "            if text:\n",
        "                before_translate.append({\n",
        "                    \"word\": text.strip(),\n",
        "                    \"start\": start,\n",
        "                    \"end\": end\n",
        "                })\n",
        "                id += 1\n",
        "            # Start a new subtitle with the combined text\n",
        "            text = combined_text\n",
        "            start = combined_start_time\n",
        "        else:\n",
        "            # Accumulate text\n",
        "            if not text:\n",
        "                start = combined_start_time\n",
        "            text += \" \" + combined_text\n",
        "\n",
        "        # Update the end timestamp\n",
        "        end = combined_end_time\n",
        "        last_end_time = end\n",
        "\n",
        "        # Move to the next word\n",
        "        i += 1\n",
        "\n",
        "    # Add the final subtitle segment if text is not empty\n",
        "    if text:\n",
        "        before_translate.append({\n",
        "            \"word\": text.strip(),\n",
        "            \"start\": start,\n",
        "            \"end\": end\n",
        "        })\n",
        "\n",
        "    return before_translate\n",
        "\n",
        "\n",
        "\n",
        "def convert_time_to_srt_format(seconds):\n",
        "    \"\"\" Convert seconds to SRT time format (HH:MM:SS,ms) \"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
        "    return f\"{hours:02}:{minutes:02}:{secs:02},{milliseconds:03}\"\n",
        "def write_subtitles_to_file(subtitles, filename=\"subtitles.srt\"):\n",
        "\n",
        "    # Open the file with UTF-8 encoding\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        for id, entry in subtitles.items():\n",
        "            # Write the subtitle index\n",
        "            f.write(f\"{id}\\n\")\n",
        "            if entry['start'] is None or entry['end'] is None:\n",
        "              print(id)\n",
        "            # Write the start and end time in SRT format\n",
        "            start_time = convert_time_to_srt_format(entry['start'])\n",
        "            end_time = convert_time_to_srt_format(entry['end'])\n",
        "            f.write(f\"{start_time} --> {end_time}\\n\")\n",
        "\n",
        "            # Write the text and speaker information\n",
        "            f.write(f\"{entry['text']}\\n\\n\")\n",
        "\n",
        "\n",
        "def word_level_srt(words_timestamp, srt_path=\"world_level_subtitle.srt\",shorts=False):\n",
        "    punctuation_pattern = re.compile(r'[.,!?;:\"\\–—_~^+*|]')\n",
        "    with open(srt_path, 'w', encoding='utf-8') as srt_file:\n",
        "        for i, word_info in enumerate(words_timestamp, start=1):\n",
        "            start_time = convert_time_to_srt_format(word_info['start'])\n",
        "            end_time = convert_time_to_srt_format(word_info['end'])\n",
        "            word=word_info['word']\n",
        "            word =re.sub(punctuation_pattern, '', word)\n",
        "            if word.strip() == 'i':\n",
        "                word = \"I\"\n",
        "            if shorts==False:\n",
        "              word=word.replace(\"-\",\"\")\n",
        "            srt_file.write(f\"{i}\\n{start_time} --> {end_time}\\n{word}\\n\\n\")\n",
        "\n",
        "\n",
        "def generate_srt_from_sentences(sentence_timestamp, srt_path=\"default_subtitle.srt\"):\n",
        "    with open(srt_path, 'w', encoding='utf-8') as srt_file:\n",
        "        for index, sentence in enumerate(sentence_timestamp):\n",
        "            start_time = convert_time_to_srt_format(sentence['start'])\n",
        "            end_time = convert_time_to_srt_format(sentence['end'])\n",
        "            srt_file.write(f\"{index + 1}\\n{start_time} --> {end_time}\\n{sentence['text']}\\n\\n\")\n",
        "\n",
        "def get_audio_file(uploaded_file):\n",
        "    global temp_folder\n",
        "    file_path = os.path.join(temp_folder, os.path.basename(uploaded_file))\n",
        "    file_path=clean_file_name(file_path)\n",
        "    shutil.copy(uploaded_file, file_path)\n",
        "    return file_path\n",
        "\n",
        "def whisper_subtitle(uploaded_file,Source_Language,max_words_per_subtitle=8):\n",
        "  global language_dict,base_path,subtitle_folder\n",
        "  #Load model\n",
        "  if torch.cuda.is_available():\n",
        "      # If CUDA is available, use GPU with float16 precision\n",
        "      device = \"cuda\"\n",
        "      compute_type = \"float16\"\n",
        "      # compute_type=\"int8_float16\"\n",
        "  else:\n",
        "      # If CUDA is not available, use CPU with int8 precision\n",
        "      device = \"cpu\"\n",
        "      compute_type = \"int8\"\n",
        "  faster_whisper_model = WhisperModel(\"deepdml/faster-whisper-large-v3-turbo-ct2\",device=device, compute_type=compute_type)\n",
        "  audio_path=get_audio_file(uploaded_file)\n",
        "  if Source_Language==\"Automatic\":\n",
        "      segments,d = faster_whisper_model.transcribe(audio_path, word_timestamps=True)\n",
        "      lang_code=d.language\n",
        "      src_lang=get_language_name(lang_code)\n",
        "  else:\n",
        "    lang=language_dict[Source_Language]['lang_code']\n",
        "    segments,d = faster_whisper_model.transcribe(audio_path, word_timestamps=True,language=lang)\n",
        "    src_lang=Source_Language\n",
        "\n",
        "  sentence_timestamp,words_timestamp,text=format_segments(segments)\n",
        "  if os.path.exists(audio_path):\n",
        "    os.remove(audio_path)\n",
        "  del faster_whisper_model\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  word_segments=combine_word_segments(words_timestamp, max_words_per_subtitle=max_words_per_subtitle, min_silence_between_words=0.5)\n",
        "  shorts_segments=custom_word_segments(words_timestamp, min_silence_between_words=0.3, max_characters_per_subtitle=17)\n",
        "  #setup srt file names\n",
        "  base_name = os.path.basename(uploaded_file).rsplit('.', 1)[0][:30]\n",
        "  save_name = f\"{subtitle_folder}/{base_name}_{src_lang}.srt\"\n",
        "  original_srt_name=clean_file_name(save_name)\n",
        "  original_txt_name=original_srt_name.replace(\".srt\",\".txt\")\n",
        "  word_level_srt_name=original_srt_name.replace(\".srt\",\"_word_level.srt\")\n",
        "  customize_srt_name=original_srt_name.replace(\".srt\",\"_customize.srt\")\n",
        "  shorts_srt_name=original_srt_name.replace(\".srt\",\"_shorts.srt\")\n",
        "\n",
        "  generate_srt_from_sentences(sentence_timestamp, srt_path=original_srt_name)\n",
        "  word_level_srt(words_timestamp, srt_path=word_level_srt_name)\n",
        "  word_level_srt(shorts_segments, srt_path=shorts_srt_name,shorts=True)\n",
        "  write_subtitles_to_file(word_segments, filename=customize_srt_name)\n",
        "  with open(original_txt_name, 'w', encoding='utf-8') as f1:\n",
        "    f1.write(text)\n",
        "  return original_srt_name,customize_srt_name,word_level_srt_name,shorts_srt_name,original_txt_name\n",
        "\n",
        "\n",
        "from utils import language_dict\n",
        "import pysrt\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def translate_text(text, Source_Language, Destination_Language):\n",
        "    \"\"\"\n",
        "    Translates the given text using GoogleTranslator.\n",
        "    \"\"\"\n",
        "    source_language = language_dict[Source_Language]['lang_code']\n",
        "    target_language = language_dict[Destination_Language]['lang_code']\n",
        "\n",
        "    # Adjust for specific language codes\n",
        "    if Destination_Language == \"Chinese\":\n",
        "        target_language = 'zh-CN'\n",
        "\n",
        "    translator = GoogleTranslator(source=source_language, target=target_language)\n",
        "    translation = translator.translate(text.strip())\n",
        "    return str(translation)\n",
        "\n",
        "def translate_subtitle(subtitles, Source_Language, Destination_Language):\n",
        "    \"\"\"\n",
        "    Translates subtitles while preserving their timing.\n",
        "    \"\"\"\n",
        "    global language_dict\n",
        "    store_text = \"\"\n",
        "    for subtitle in subtitles:\n",
        "        # Translate the text of each subtitle\n",
        "        text_translated = translate_text(subtitle.text, Source_Language, Destination_Language)\n",
        "        subtitle.text = text_translated  # Update the subtitle text\n",
        "        store_text += text_translated.strip() + \" \"  # Use translated text for storing\n",
        "\n",
        "    return subtitles, store_text\n",
        "\n",
        "\n",
        "#@title Using Gradio Interface\n",
        "def subtitle_maker(Audio_or_Video_File,Source_Language,Destination_Language,max_words_per_subtitle):\n",
        "  try:\n",
        "    default_srt_path,customize_srt_path,word_level_srt_path,shorts_srt_name,text_path=whisper_subtitle(Audio_or_Video_File,Source_Language,max_words_per_subtitle=max_words_per_subtitle)\n",
        "  except Exception as e:\n",
        "    print(f\"Error in whisper_subtitle: {e}\")\n",
        "    default_srt_path,customize_srt_path,word_level_srt_path,shorts_srt_name,text_path=None,None,None,None,None\n",
        "  global subtitle_folder\n",
        "  if Source_Language!=Destination_Language:\n",
        "    subtitles = pysrt.open(default_srt_path, encoding='utf-8')\n",
        "    translated_subtitles, _ = translate_subtitle(subtitles, Source_Language, Destination_Language)\n",
        "    tra_srt_name=os.path.basename(default_srt_path).replace(\".srt\",f\"_{Destination_Language}.srt\")\n",
        "    output_srt_path=f\"{subtitle_folder}/{tra_srt_name}\"\n",
        "    translated_subtitles.save(output_srt_path, encoding='utf-8')\n",
        "  else:\n",
        "    output_srt_path=None\n",
        "\n",
        "  return default_srt_path,output_srt_path,customize_srt_path,word_level_srt_path,shorts_srt_name,text_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "import click\n",
        "\n",
        "base_path=\".\"\n",
        "subtitle_folder=f\"{base_path}/generated_subtitle\"\n",
        "temp_folder = f\"{base_path}/subtitle_audio\"\n",
        "\n",
        "if not os.path.exists(subtitle_folder):\n",
        "    os.makedirs(subtitle_folder, exist_ok=True)\n",
        "if not os.path.exists(temp_folder):\n",
        "    os.makedirs(temp_folder, exist_ok=True)\n",
        "\n",
        "source_lang_list = ['Automatic']\n",
        "available_language=language_dict.keys()\n",
        "source_lang_list.extend(available_language)\n",
        "\n",
        "\n",
        "\n",
        "@click.command()\n",
        "@click.option(\"--debug\", is_flag=True, default=False, help=\"Enable debug mode.\")\n",
        "@click.option(\"--share\", is_flag=True, default=False, help=\"Enable sharing of the interface.\")\n",
        "def main(debug, share):\n",
        "    description = \"\"\"**Note**: Avoid uploading large video files. Instead, upload the audio from the video for faster processing.\n",
        "    You can find the model at [faster-whisper-large-v3-turbo-ct2](https://huggingface.co/deepdml/faster-whisper-large-v3-turbo-ct2)\"\"\"\n",
        "    # Define Gradio inputs and outputs\n",
        "    gradio_inputs = [\n",
        "        gr.File(label=\"Upload Audio or Video File\"),\n",
        "        gr.Dropdown(label=\"Source Language\", choices=source_lang_list, value=\"Automatic\"),\n",
        "        gr.Dropdown(label=\"Translate Into\", choices=source_lang_list, value=\"English\"),\n",
        "\n",
        "        gr.Number(label=\"Max Word Per Subtitle Segment [Useful for Vertical Videos]\", value=8)\n",
        "    ]\n",
        "\n",
        "    gradio_outputs = [\n",
        "        gr.File(label=\"Default SRT File\", show_label=True),\n",
        "        gr.File(label=\"Translated SRT File\", show_label=True),\n",
        "        gr.File(label=\"Customize SRT File\", show_label=True),\n",
        "        gr.File(label=\"Word Level SRT File\", show_label=True),\n",
        "        gr.File(label=\"SRT File For Shorts\", show_label=True),\n",
        "        gr.File(label=\"Text File\", show_label=True)\n",
        "    ]\n",
        "\n",
        "    # Create Gradio interface\n",
        "    demo = gr.Interface(fn=subtitle_maker, inputs=gradio_inputs, outputs=gradio_outputs, title=\"Auto Subtitle Generator Using Whisper-Large-V3-Turbo-Ct2\",description=description)\n",
        "\n",
        "    # Launch Gradio with command-line options\n",
        "    demo.queue().launch(debug=debug, share=share)\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ownYtpGp_Cw_",
        "outputId": "4b30340b-eb00-4b46-b754-7834a9671276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Usage: colab_kernel_launcher.py [OPTIONS]\n",
            "Try 'colab_kernel_launcher.py --help' for help.\n",
            "\n",
            "Error: No such option: -f\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/parser.py\", line 516, in _process_opts\n",
            "    self._match_long_opt(norm_long_opt, explicit_value, state)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/parser.py\", line 400, in _match_long_opt\n",
            "    raise NoSuchOption(opt, possibilities=possibilities, ctx=self.ctx)\n",
            "click.exceptions.NoSuchOption: No such option: -f\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1081, in main\n",
            "    with self.make_context(prog_name, args, **extra) as ctx:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 949, in make_context\n",
            "    self.parse_args(ctx, args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1414, in parse_args\n",
            "    opts, args, param_order = parser.parse_args(args=args)\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/parser.py\", line 339, in parse_args\n",
            "    self._process_args_for_options(state)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/parser.py\", line 366, in _process_args_for_options\n",
            "    self._process_opts(arg, state)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/parser.py\", line 525, in _process_opts\n",
            "    self._match_short_opt(arg, state)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/parser.py\", line 438, in _match_short_opt\n",
            "    raise NoSuchOption(opt, ctx=self.ctx)\n",
            "click.exceptions.NoSuchOption: No such option: -f\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-21-8e78db5c6418>\", line 422, in <cell line: 0>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1161, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1100, in main\n",
            "    sys.exit(e.exit_code)\n",
            "SystemExit: 2\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1671, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNoSuchOption\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/parser.py\u001b[0m in \u001b[0;36m_process_opts\u001b[0;34m(self, arg, state)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_long_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_long_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNoSuchOption\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/parser.py\u001b[0m in \u001b[0;36m_match_long_opt\u001b[0;34m(self, opt, explicit_value, state)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mpossibilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_close_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_long_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchOption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibilities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpossibilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNoSuchOption\u001b[0m: No such option: -f",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNoSuchOption\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/core.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self, args, prog_name, complete_var, standalone_mode, windows_expand_args, **extra)\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                     \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/core.py\u001b[0m in \u001b[0;36mmake_context\u001b[0;34m(self, info_name, args, parent, **extra)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/core.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m         \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/parser.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_args_for_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_args_for_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/parser.py\u001b[0m in \u001b[0;36m_process_args_for_options\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_prefixes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marglen\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_interspersed_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/parser.py\u001b[0m in \u001b[0;36m_process_opts\u001b[0;34m(self, arg, state)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_prefixes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_short_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/parser.py\u001b[0m in \u001b[0;36m_match_short_opt\u001b[0;34m(self, arg, state)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchOption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtakes_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNoSuchOption\u001b[0m: No such option: -f",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-8e78db5c6418>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;34m\"\"\"Alias for :meth:`main`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/core.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self, args, prog_name, complete_var, standalone_mode, windows_expand_args, **extra)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 2",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysrt>=1.1.2\n",
        "!pip install deep_translator==1.11.4\n"
      ],
      "metadata": {
        "id": "bg-qKnr-0-6k",
        "outputId": "f0fd070d-95af-432d-b55c-e7de85ef758b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep_translator==1.11.4\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep_translator==1.11.4) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep_translator==1.11.4) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator==1.11.4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator==1.11.4) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator==1.11.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator==1.11.4) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator==1.11.4) (2024.12.14)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep_translator\n",
            "Successfully installed deep_translator-1.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dLYCcOIf4OHC",
        "outputId": "5511a7f7-dc95-4a4e-cf06-dbbea1242680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'en'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "def translate_text(text, Source_Language,Destination_Language):\n",
        "    # print(\"calling translate\")\n",
        "    source_language=language_dict[Source_Language]['lang_code']\n",
        "    target_language=language_dict[Destination_Language]['lang_code']\n",
        "    if Destination_Language == \"Chinese\":\n",
        "          target_language='zh-CN'\n",
        "    translator = GoogleTranslator(source=source_language,target=target_language)\n",
        "    translation = translator.translate(text.strip())\n",
        "    t_text=str(translation)\n",
        "    # print(f\"{t_text}---{Language}----{target_language}\")\n",
        "    return t_text\n"
      ],
      "metadata": {
        "id": "hZZKeWdz38iP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import language_dict\n",
        "import pysrt\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def translate_text(text, Source_Language, Destination_Language):\n",
        "    \"\"\"\n",
        "    Translates the given text using GoogleTranslator.\n",
        "    \"\"\"\n",
        "    source_language = language_dict[Source_Language]['lang_code']\n",
        "    target_language = language_dict[Destination_Language]['lang_code']\n",
        "\n",
        "    # Adjust for specific language codes\n",
        "    if Destination_Language == \"Chinese\":\n",
        "        target_language = 'zh-CN'\n",
        "\n",
        "    translator = GoogleTranslator(source=source_language, target=target_language)\n",
        "    translation = translator.translate(text.strip())\n",
        "    return str(translation)\n",
        "\n",
        "def translate_subtitle(subtitles, Source_Language, Destination_Language):\n",
        "    \"\"\"\n",
        "    Translates subtitles while preserving their timing.\n",
        "    \"\"\"\n",
        "    global language_dict\n",
        "    store_text = \"\"\n",
        "    for subtitle in subtitles:\n",
        "        # Translate the text of each subtitle\n",
        "        text_translated = translate_text(subtitle.text, Source_Language, Destination_Language)\n",
        "        subtitle.text = text_translated  # Update the subtitle text\n",
        "        store_text += text_translated.strip() + \" \"  # Use translated text for storing\n",
        "\n",
        "    return subtitles, store_text\n",
        "\n",
        "def main(input_srt_path, output_srt_path, Source_Language, Destination_Language):\n",
        "    \"\"\"\n",
        "    Main function to translate subtitles from an input SRT file and save to an output file.\n",
        "    \"\"\"\n",
        "    # Read the subtitles\n",
        "    subtitles = pysrt.open(input_srt_path, encoding='utf-8')\n",
        "\n",
        "    # Translate subtitles\n",
        "    translated_subtitles, _ = translate_subtitle(subtitles, Source_Language, Destination_Language)\n",
        "\n",
        "    # Write the translated subtitles to a new SRT file\n",
        "    translated_subtitles.save(output_srt_path, encoding='utf-8')\n",
        "    print(f\"Translation complete. Output written to {output_srt_path}\")\n",
        "\n",
        "# Example usage\n",
        "input_srt = \"/content/long.srt\"\n",
        "output_srt = \"/content/translated_output.srt\"\n",
        "main(input_srt, output_srt, \"English\", \"Bengali\")\n"
      ],
      "metadata": {
        "id": "ybBUfBe31rf8",
        "outputId": "70d0473b-bd2a-456f-bc53-f7a3600af704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation complete. Output written to /content/translated_output.srt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path=\".\"\n",
        "subtitle_folder=f\"{base_path}/generated_subtitle\""
      ],
      "metadata": {
        "id": "7GeHN9Ba9FVd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_srt = \"/content/long.srt\"\n",
        "Destination_Language=\"english\"\n",
        "import os\n",
        "os.path.basename(input_srt).replace(\".srt\",f\"_{Destination_Language}.srt\")\n"
      ],
      "metadata": {
        "id": "hAzDJ2wC9Gqm",
        "outputId": "fc793af6-a495-4a61-bb43-8fa52d633809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'long_english.srt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import language_dict\n",
        "import pysrt\n",
        "from deep_translator import GoogleTranslator\n",
        "from tqdm import tqdm\n",
        "\n",
        "def translate_batch(texts, source_lang, target_lang, chunk_size=2000):\n",
        "    \"\"\"\n",
        "    Translate a batch of texts into the target language using chunks.\n",
        "    \"\"\"\n",
        "    if not texts:\n",
        "        return []\n",
        "\n",
        "    translator = GoogleTranslator(source=source_lang, target=target_lang)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    chunk_texts = []\n",
        "    results = []\n",
        "\n",
        "    # Split texts into chunks based on character limits\n",
        "    for text in texts:\n",
        "        if len(current_chunk) + len(text) <= chunk_size:\n",
        "            if current_chunk:\n",
        "                current_chunk += \" ||||| \"  # Separator to reconstruct order\n",
        "            current_chunk += text\n",
        "            chunk_texts.append(text)\n",
        "        else:\n",
        "            chunks.append((current_chunk, chunk_texts))\n",
        "            current_chunk = text\n",
        "            chunk_texts = [text]\n",
        "    if current_chunk:\n",
        "        chunks.append((current_chunk, chunk_texts))\n",
        "\n",
        "    # Translate each chunk and reconstruct\n",
        "    for chunk, chunk_texts in tqdm(chunks, desc=\"Translating\"):\n",
        "        try:\n",
        "            translated_chunk = translator.translate(chunk)\n",
        "            translated_texts = translated_chunk.split(\"|||||\")\n",
        "            if len(translated_texts) == len(chunk_texts):\n",
        "                results.extend(translated_texts)\n",
        "            else:\n",
        "                # Fallback to iterative translation for this chunk\n",
        "                for text in chunk_texts:\n",
        "                    results.append(translator.translate(text.strip()))\n",
        "        except Exception as e:\n",
        "            print(f\"Translation error: {e}\")\n",
        "            # Retry iteratively if chunk fails\n",
        "            for text in chunk_texts:\n",
        "                results.append(translator.translate(text.strip()))\n",
        "\n",
        "    return results\n",
        "\n",
        "def translate_subtitle(subtitles, Source_Language, Destination_Language, chunk_size=2000):\n",
        "    \"\"\"\n",
        "    Translates subtitles in batches while preserving their timing.\n",
        "    \"\"\"\n",
        "    # Extract texts\n",
        "    texts = [subtitle.text for subtitle in subtitles]\n",
        "\n",
        "    # Get language codes\n",
        "    source_lang = language_dict[Source_Language]['lang_code']\n",
        "    target_lang = language_dict[Destination_Language]['lang_code']\n",
        "    if Destination_Language == \"Chinese\":\n",
        "        target_lang = 'zh-CN'\n",
        "\n",
        "    # Translate in batches\n",
        "    translated_texts = translate_batch(texts, source_lang, target_lang, chunk_size)\n",
        "\n",
        "    # Update subtitles with translated texts\n",
        "    for subtitle, translated_text in zip(subtitles, translated_texts):\n",
        "      text = translated_text.strip()\n",
        "      if text.startswith(\"|\"):\n",
        "          text = text[1:]\n",
        "      subtitle.text = text.strip()\n",
        "    return subtitles\n",
        "\n",
        "def main(input_srt_path, output_srt_path, Source_Language, Destination_Language, chunk_size=2000):\n",
        "    \"\"\"\n",
        "    Main function to translate subtitles from an input SRT file and save to an output file.\n",
        "    \"\"\"\n",
        "    # Read subtitles\n",
        "    subtitles = pysrt.open(input_srt_path, encoding='utf-8')\n",
        "\n",
        "    # Translate subtitles\n",
        "    translated_subtitles = translate_subtitle(subtitles, Source_Language, Destination_Language, chunk_size)\n",
        "\n",
        "    # Save translated subtitles\n",
        "    translated_subtitles.save(output_srt_path, encoding='utf-8')\n",
        "    print(f\"Translation complete. Output written to {output_srt_path}\")\n",
        "\n",
        "# Example usage\n",
        "input_srt = \"/content/long.srt\"\n",
        "output_srt = \"/content/translated_output2.srt\"\n",
        "main(input_srt, output_srt, \"English\", \"Bengali\")\n"
      ],
      "metadata": {
        "id": "x9y5tlrh5cXd",
        "outputId": "95f115b5-6ee0-4042-e2ac-03874d384674",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating: 100%|██████████| 8/8 [00:14<00:00,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation complete. Output written to /content/translated_output2.srt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}